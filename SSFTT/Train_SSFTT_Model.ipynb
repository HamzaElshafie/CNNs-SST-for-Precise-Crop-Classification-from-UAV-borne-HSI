{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from operator import truediv\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os\n",
    "import zipfile\n",
    "import argparse\n",
    "import scipy.io as sio\n",
    "import SSFTTnet\n",
    "import get_cls_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/rupeshkumaryadav/whu-hyperspectral-dataset\n",
      "Downloaded and extracted the dataset WHU-Hi-HanChuan to /Users/hamzaelshafie/Desktop/Research Project/Codebase/Spectral-Spatial-Transformers-for-Precise-Crop-Classification-from-UAV-borne-Hyperspectral-Images/Data\n",
      "Loading data from /Users/hamzaelshafie/Desktop/Research Project/Codebase/Spectral-Spatial-Transformers-for-Precise-Crop-Classification-from-UAV-borne-Hyperspectral-Images/Data/WHU-Hi-HanChuan/WHU_Hi_HanChuan.mat\n",
      "Loading labels from /Users/hamzaelshafie/Desktop/Research Project/Codebase/Spectral-Spatial-Transformers-for-Precise-Crop-Classification-from-UAV-borne-Hyperspectral-Images/Data/WHU-Hi-HanChuan/WHU_Hi_HanChuan_gt.mat\n",
      "Keys in data_mat: ['__header__', '__version__', '__globals__', 'WHU_Hi_HanChuan']\n",
      "Keys in labels_mat: ['__header__', '__version__', '__globals__', 'WHU_Hi_HanChuan_gt']\n",
      "Available keys in data_mat: ['__header__', '__version__', '__globals__', 'WHU_Hi_HanChuan']\n",
      "Available keys in labels_mat: ['__header__', '__version__', '__globals__', 'WHU_Hi_HanChuan_gt']\n",
      "Data shape: (1217, 303, 274)\n",
      "Labels shape: (1217, 303)\n"
     ]
    }
   ],
   "source": [
    "main_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(main_dir)\n",
    "\n",
    "from data_fetcher import loadData\n",
    "\n",
    "dataset_mapping = {\n",
    "    'HanChuan': 'WHU-Hi-HanChuan',\n",
    "    'HongHu': 'WHU-Hi-HongHu',\n",
    "    'LongKou': 'WHU-Hi-LongKou'\n",
    "}\n",
    "\n",
    "def loadDataWrapper(dataset, kaggle_json_path, base_path):\n",
    "    dataset_name = dataset_mapping[dataset]\n",
    "    data, labels = loadData(dataset_name, kaggle_json_path, base_path)\n",
    "    \n",
    "    return data, labels\n",
    "\n",
    "class Args:\n",
    "    def __init__(self, dataset, kaggle_json_path):\n",
    "        self.dataset = dataset\n",
    "        self.kaggle_json_path = kaggle_json_path\n",
    "\n",
    "args = Args(dataset='HanChuan', kaggle_json_path='~/.kaggle/kaggle.json')\n",
    "base_path = os.path.abspath(os.path.join(main_dir, 'Data'))\n",
    "# Use loadDataWrapper to load data and labels\n",
    "data, labels = loadDataWrapper(args.dataset, args.kaggle_json_path, base_path)\n",
    "\n",
    "print('Data shape:', data.shape)\n",
    "print('Labels shape:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
